{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Week 5 - Assignment</center></h2>\n",
    "<h3><center>Programming for Data Science 2024</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises for the topics covered in the fifth lecture.\n",
    "\n",
    "The exercise will be marked as passed if you get **at least 10/15** points.\n",
    "\n",
    "Exercises must be handed in via **ILIAS** (Homework assignments). Deliver your submission as a compressed file (zip) containing one .py or .ipynb file with all exercises. The name of both the .zip and the .py/.ipynb file **must** be *SurnameName* of the two members of the group. Example: Riccardo Cusinato + Athina Tzovara = *CusinatoRiccardo_TzovaraAthina.zip* .\n",
    "\n",
    "It's important to use comments to explain your code and show that you're able to take ownership of the exercises and discuss them.\n",
    "\n",
    "You are not expected to collaborate outside of the group on exercises and submitting other groupsâ€™ code as your own will result in 0 points.\n",
    "\n",
    "For questions contact: *riccardo.cusinato@unibe.ch* with the subject: *Programming for Data Science 2024*.\n",
    "\n",
    "**Deadline: 14:00, March 28, 2024.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Exercise 1 - Fitbit dataset<span style=\"float: right\">3 points</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with three datasets - 'activity.csv', 'calories.csv', and 'last_participant.csv', which contains activity tracker data from https://www.kaggle.com/datasets/arashnic/fitbit\n",
    "\n",
    "If you are unable to do this exercise, you can load the dataset 'combined_solution.csv' for the next exercise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Data preparation** (*1 point*)\n",
    "\n",
    "    - Load the two datasets 'activity.csv' and 'calories.csv'.\n",
    "    - Use pd.to_datetime to standardize the ActivityDate columns (https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04.12.16\n",
      "2016-04-12 00:00:00\n",
      "04.12.16\n",
      "2016-04-12 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#load data set\n",
    "activity_ds = pd.read_csv('data/activity.csv') \n",
    "calories_ds = pd.read_csv('data/calories.csv')\n",
    "\n",
    "#standardize ActivityDate column for each dataset, check the format befor and after to be sure it worked\n",
    "for ds in [activity_ds, calories_ds]: \n",
    "    print(ds[\"ActivityDate\"][0])\n",
    "    ds[\"ActivityDate\"] = pd.to_datetime(ds[\"ActivityDate\"], format=\"mixed\")\n",
    "    print(ds[\"ActivityDate\"][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Merging** (*1 point*)\n",
    "\n",
    "    - Consider what information is shared between the two datasets and merge them. Keep in mind that the order of rows is not the same in both datasets!\n",
    "    - Print out the mean \"TotalSteps\" of the merged DataFrame at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 'TotalSteps': 7786.44\n"
     ]
    }
   ],
   "source": [
    "# two things are shared between the datasets: ID and ActivityDate\n",
    "activity_calories = pd.merge(activity_ds, calories_ds, on=[\"ID\", \"ActivityDate\"], how = \"inner\" )\n",
    "# Mean of TotalSteps:\n",
    "print(f\"Mean of 'TotalSteps': {activity_calories[\"TotalSteps\"].mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Concatenation** (*1 point*)\n",
    "\n",
    "    - The data of one additional participant exists in 'last_participant.csv'. Load this dataset and concatenate it with the merged dataset generated above\n",
    "    - Print out the mean \"TotalSteps\" again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 'TotalSteps': 7879.46\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "last_participant_ds = pd.read_csv('data/last_participant.csv')\n",
    "# Standardize ActivityDate (we don't really need it for the task)\n",
    "last_participant_ds[\"ActivityDate\"] = pd.to_datetime(last_participant_ds[\"ActivityDate\"], format=\"mixed\")\n",
    "\n",
    "# Concatenate\n",
    "total_dataset = pd.concat([activity_calories, last_participant_ds], join = \"inner\")\n",
    "\n",
    "# print mean of TotalSteps\n",
    "print(f\"Mean of 'TotalSteps': {total_dataset[\"TotalSteps\"].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Exercise 2 - Working with missing data<span style=\"float: right\">5 points</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our dataset, some values are missing from the 'TotalSteps' and 'Calories' columns.\n",
    "\n",
    "We can try to approximate these missing values with the data we got. \n",
    "\n",
    "You can load the dataset 'combined_solution.csv' if you were unable to complete the previous exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Filling in missing values** (*3 points*)\n",
    "\n",
    "    - Calculate the mean steps per calory burnt and mean calories burnt per step, by averaging across all observations in the dataset and then computing the ratio. Print out both values.\n",
    "    - Fill in the null values in the columns 'Calories' and 'TotalSteps' where possible. To fill the values you have to use the factors *\"TotalSteps/Calories\"* and *\"Calories/TotalSteps\"* calculated in the previous point, using one of the two information to fill the other.\n",
    "    - Print out the mean of the columns 'TotalSteps' and 'Calories' before and after filling the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean steps per calory (TotalSteps/Calories): 3.41\n",
      "Mean calories per step (Calories/TotalSteps): 0.293251\n",
      "\n",
      "Before filtering:\n",
      "Mean calories = 2310.66\n",
      "Mean steps = 7879.46\n",
      "\n",
      "After filtering:\n",
      "Mean calories = 2302.94\n",
      "Mean steps = 7785.91\n"
     ]
    }
   ],
   "source": [
    "# I just put the creation of the dataset here so if we re-run the cell, it reset total_dataset \n",
    "#(if we don't do that, before and after filtering will be the same when re-runing)\n",
    "total_dataset = pd.concat([activity_calories, last_participant_ds], join = \"inner\") \n",
    "\n",
    "# mean TotalSteps/Calories\n",
    "mean_steps_per_calory = total_dataset[\"TotalSteps\"].mean()/total_dataset[\"Calories\"].mean()\n",
    "# mean Calories/TotalSteps\n",
    "mean_calories_per_step = total_dataset[\"Calories\"].mean()/total_dataset[\"TotalSteps\"].mean()\n",
    "# print both values\n",
    "print(f\"Mean steps per calory (TotalSteps/Calories): {mean_steps_per_calory:.2f}\\nMean calories per step (Calories/TotalSteps): {mean_calories_per_step:2f}\\n\")\n",
    "# mean of calories and Total steps before filtering\n",
    "print(f\"Before filtering:\\nMean calories = {total_dataset[\"Calories\"].mean():.2f}\\nMean steps = {total_dataset[\"TotalSteps\"].mean():.2f}\\n\")\n",
    "\n",
    "# fill NA when possible (I created new columns)\n",
    "total_dataset[\"TotalSteps\"] = total_dataset[\"TotalSteps\"].fillna(total_dataset[\"Calories\"]*mean_steps_per_calory)\n",
    "total_dataset[\"Calories\"] = total_dataset[\"Calories\"].fillna(total_dataset[\"TotalSteps\"]*mean_calories_per_step)\n",
    "\n",
    "print(f\"After filtering:\\nMean calories = {total_dataset[\"Calories\"].mean():.2f}\\nMean steps = {total_dataset[\"TotalSteps\"].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Dropping missing values** (*2 points*)\n",
    "\n",
    "    - Print how many null values there are in the 'Calories' and 'TotalSteps' columns, respectively.\n",
    "    - Drop the rows where **both** 'Calories' and 'TotalSteps' are missing.\n",
    "    - Print number of rows in the final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values for Calories: 13\n",
      "Number of missing values for TotalSteps: 13\n",
      "Number of rows before dropping: 969\n",
      "Number of rows after dropping: 956\n"
     ]
    }
   ],
   "source": [
    "# print number of null values\n",
    "missing_cal = total_dataset[\"Calories\"].isnull().sum()\n",
    "missing_steps = total_dataset[\"TotalSteps\"].isnull().sum()\n",
    "print(f\"Number of missing values for Calories: {missing_cal}\\nNumber of missing values for TotalSteps: {missing_steps}\")\n",
    "\n",
    "# number of rows before dropping (just for us to check that we actually drop rows)\n",
    "print(f\"Number of rows before dropping: {len(total_dataset)}\")\n",
    "\n",
    "# drop values where both Calories and TotalSteps are missing\n",
    "total_dataset.dropna(subset = [\"Calories\",\"TotalSteps\"], how=\"all\", inplace = True)\n",
    "\n",
    "# number of rows after dropping\n",
    "print(f\"Number of rows after dropping: {len(total_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Exercise 3 - Multi-index<span style=\"float: right\">7 points</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will create and manipulate a multi-index dataframe. First, let's create the dataframe for the exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"idx\": [0, 1, 2],\n",
    "        \"A_X\": [1.1, 1.1, 1.1],\n",
    "        \"A_Y\": [1.2, 1.2, 1.2],\n",
    "        \"B_X\": [1.11, 1.11, 1.11],\n",
    "        \"B_Y\": [1.22, 1.22, 1.22],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set the column *idx* as the index of the dataframe. (*1 point*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# YOUR CODE HERE\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a multi-column stucture. (*3 points*)\n",
    "    - Set the columns *A, B* on the first level and *X, Y* on the second level, taken from the combinations in the original dataframe. \n",
    "    - Set the names of the two new levels as \"L1\" and \"L2\", respectively. \n",
    "    - Print the resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# YOUR CODE HERE\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. From the previous dataframe, re-create a dataframe with a single column level. (*3 points*)\n",
    "    - Create a new column from the first level (L1) of the multi-column. At this point your columns should be ['L1', 'X', 'Y'], with name 'L2'. **NB** The DataFrame method *reset_index* is useful for this part.\n",
    "    - Rename the newly-created column as \"letter\" and the name of the column level as \"L\". Use the appropiate pandas methods for this.\n",
    "    - Print the resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# YOUR CODE HERE\n",
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
